# v1-MVP 서버 성능 장애 트러블슈팅 보고서

## 개요

| 항목 | 내용 |
|------|------|
| **기간** | 2026-02-02 ~ 2026-02-09 |
| **환경** | Production (EC2), Dev |
| **서비스** | Tasteam 검색 API (`/api/v1/search`) |
| **기술 스택** | Spring Boot, HikariCP, PostgreSQL, Caddy, Loki, Prometheus |

Production 환경에서 HikariCP 커넥션 풀 고갈로 서비스가 약 1시간 40분간 중단되었다.
이후 부하 테스트를 통해 DEBUG 로그 폭주, 웹훅 폭주, 트랜잭션 설계 결함, 검색 쿼리 성능 문제를 추가로 발견하고 순차적으로 해결했다.

최종적으로 1,000 VU 부하에서 **성공률 0% → 100%**, **P95 응답 시간 30s → 3.82s**로 개선되었다.

---

## 장애 타임라인

| 일시 | 이벤트 | 심각도 |
|------|--------|--------|
| 02-02 18:21 | Production 커넥션 풀 고갈, 서비스 중단 | Critical |
| 02-02 20:00 | 장애 감지 (수동 로그 확인) | - |
| 02-02 20:20 | HikariCP 설정 추가 (10 → 50), 재배포 | - |
| 02-05 11:36 | 부하 테스트 중 DEBUG 로그 폭주로 서버 다운 | Critical |
| 02-05 11:36 | Discord 웹훅 Rate Limit 폭주 발견 | High |
| 02-05 13:40 | 로그 레벨 INFO 전환 + 비동기 Appender 적용 | - |
| 02-05 15:20 | REQUIRES_NEW 커넥션 2배 소비 문제 발견 | High |
| 02-05 16:28 | 비동기 처리 전환 + 유니크 인덱스 적용 | - |
| 02-08 | 검색 쿼리 최적화 (pg_trgm + GIN 인덱스) | - |
| 02-09 | 최종 부하 테스트 검증 완료 | - |

---

## 1. HikariCP 커넥션 풀 고갈 (Production)

### 현상

2월 2일 18:21:45, 애플리케이션 로그가 완전히 멈추고 약 1시간 40분간 새로운 로그가 기록되지 않았다.
웹사이트 자체는 접속 가능했고, 헬스체크(`/actuator/health`)도 200 OK를 반환해 장애 인지가 지연되었다.

```
HikariPool-1 - Connection is not available, request timed out after 30000ms
(total=10, active=10, idle=0, waiting=78)
```

### 원인

Spring Boot HikariCP 기본값(`maximum-pool-size: 10`)을 그대로 사용하고 있었다.
동시 요청이 10개를 초과하면서 모든 커넥션이 점유되고, 대기 요청 78개가 30초 타임아웃 후 순차적으로 실패했다.

```yaml
# application.prod.yml (수정 전) - hikari 설정 없음
spring:
  datasource:
    url: ${DB_URL}
    username: ${DB_USERNAME}
    password: ${DB_PASSWORD}
```

### 조치

```yaml
# application.prod.yml (수정 후)
spring:
  datasource:
    hikari:
      maximum-pool-size: 50
      minimum-idle: 10
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000
      leak-detection-threshold: 60000
```

### 부수 문제: 헬스체크의 불완전성

커넥션 풀이 완전히 고갈된 상태에서도 `/actuator/health`가 200 OK를 반환했다.
기본 헬스체크가 실제 DB 커넥션을 획득하지 않아, 서비스 불가 상태를 감지하지 못했다.

---

## 2. DEBUG 로그 폭주로 인한 Disk I/O 과부하

### 현상

Dev 환경에서 Python 3000 쓰레드 부하 테스트 시 **20초만에 서버가 다운**되었다.
Grafana에서 CPU 사용률은 40%인데 Load Average는 100%로 I/O 대기가 원인임을 확인했다.

### 원인

Non-prod 환경에서 `root level="DEBUG"`로 설정되어 있어, 모든 third-party 라이브러리의 DEBUG 로그가 출력되고 있었다.

- **Hibernate**: 쿼리 변환 과정마다 수십 개의 DEBUG 로그
- **AWS SDK**: S3 presigned URL 서명 계산 과정 전체 출력 (보안 정보 포함)
- **HikariCP**: 커넥션 풀 상태 매번 기록

동기 방식 파일 Appender를 사용하고 있어 로그 기록이 Tomcat 스레드를 블로킹했다.

### 조치

**1) 로그 레벨 변경** - Root 레벨을 DEBUG → INFO로 변경하고, 자체 애플리케이션(`com.tasteam`)만 DEBUG 허용

**2) Third-party 로그 제한**

```xml
<logger name="org.hibernate.orm" level="WARN" />
<logger name="com.amazonaws" level="WARN" />
<logger name="com.zaxxer.hikari" level="INFO" />
```

**3) 비동기 Appender 적용**

```xml
<appender name="ASYNC_JSON_FILE" class="ch.qos.logback.classic.AsyncAppender">
    <appender-ref ref="JSON_FILE" />
    <queueSize>2048</queueSize>
    <discardingThreshold>410</discardingThreshold>
    <neverBlock>true</neverBlock>
    <maxFlushTime>5000</maxFlushTime>
</appender>
```

### 결과

| 지표 | 적용 전 | 적용 후 |
|------|---------|---------|
| Disk I/O Utilization | 8-10% | ~0% |
| /run 메모리 사용량 | 762 MiB | 1.51 MiB |
| 서버 생존 시간 | 20초 | 지속 유지 |

---

## 3. Discord 웹훅 폭주

### 현상

부하 테스트 중 대량의 에러가 발생하면서 각 에러마다 Discord 웹훅을 전송, Discord Rate Limit(429)이 발동되었다.
재시도 실패 로그가 추가로 쌓이는 악순환이 발생하고, Virtual Thread가 1,600개 이상 생성되어 리소스를 소비했다.

### 조치

부하 테스트 시 `tasteam.webhook.enabled: false`로 웹훅 비활성화.
`@ConditionalOnProperty`로 Bean 등록 자체를 차단하여 근본적으로 방지했다.

---

## 4. REQUIRES_NEW 트랜잭션으로 인한 커넥션 2배 소비

### 현상

k6 500 VU 부하 테스트에서 **성공률 0%**, 모든 요청이 커넥션 타임아웃으로 실패했다.

```
HikariPool-1 - Connection is not available, request timed out after 30000ms
(total=50, active=50, idle=0, waiting=199)
```

커넥션을 50개로 늘렸음에도 고갈이 발생했고, 부하 테스트가 끝난 후에도 지속되었다.

### 원인

검색 API의 트랜잭션 구조가 한 요청당 **커넥션 2개를 동시에 점유**하고 있었다.

```
SearchService.search()              ← @Transactional(readOnly=true), 커넥션 1
  └─ SearchHistoryRecorder          ← @Transactional(REQUIRES_NEW), 커넥션 2
      .recordSearchHistory()           (부모 커넥션은 반환되지 않고 대기)
```

실제 처리 가능 요청: 50 / 2 = **25개**. 나머지는 모두 커넥션 대기 후 타임아웃.

50개 요청이 모두 커넥션 1을 점유한 상태에서 커넥션 2를 요청하면, 풀에 여유가 없어 서로 대기하는 **Circular Wait** 상태가 발생했다.

### 추가 병목: 동시성 문제

같은 사용자가 동일 키워드를 동시에 검색할 경우 Race Condition이 발생했다.
두 트랜잭션 모두 "없음"을 확인하고 중복 INSERT를 시도하거나, 같은 행의 ROW LOCK을 대기하며 커넥션 점유 시간이 증가했다.

### 조치

**1) REQUIRES_NEW 제거, 비동기 처리 전환**

```java
// Before
@Transactional(propagation = Propagation.REQUIRES_NEW)
public void recordSearchHistory(Long memberId, String keyword) { ... }

// After
@Async("searchHistoryExecutor")
@Transactional
public void recordSearchHistory(Long memberId, String keyword) { ... }
```

전용 스레드풀(`searchHistoryExecutor`)을 도입하여 메인 트랜잭션과 완전히 분리했다.
부모 트랜잭션이 자식의 완료를 기다리지 않으므로 커넥션 1개만 사용하게 되었다.

**2) 유니크 인덱스 추가 (동시성 해결)**

Flyway 마이그레이션으로 `(member_id, keyword, deleted_at)` 유니크 인덱스를 추가하여 중복 INSERT를 방지했다.

**3) 커넥션 타임아웃 단축**

```yaml
spring.datasource.hikari.connection-timeout: 10000  # 30s → 10s
```

빠른 실패로 리소스 점유 시간을 줄이고, 다른 요청에게 기회를 제공했다.

---

## 5. 검색 쿼리 성능 문제 (Full Table Scan)

### 현상

검색 쿼리 한 건에 5~10초가 소요되어 커넥션 점유 시간이 길어지고, 커넥션 풀 고갈을 가속화했다.

### 원인

양쪽 와일드카드 LIKE 검색으로 인덱스를 사용할 수 없었다.

```sql
SELECT * FROM restaurant
WHERE deleted_at IS NULL
  AND (LOWER(name) LIKE '%피자%' OR LOWER(full_address) LIKE '%피자%')
ORDER BY updated_at DESC
LIMIT 10;
```

### 조치

**1) pg_trgm(GIN) + GiST(공간) 인덱스 추가**

Flyway 마이그레이션으로 트라이그램 인덱스와 공간 인덱스를 추가했다.

- `V20260208__add_trgm_indexes_restaurant.sql`
- `V20260208__add_location_gist_index.sql`
- `V20260208__add_hybrid_indexes_restaurant.sql`

**2) QueryDSL 기반 후보군 전략**

전체 테이블을 스캔하는 대신, 상위 200개 후보군만 추출한 뒤 가중치 점수로 재정렬하는 Two-Step 전략을 적용했다.

- 이름 완전일치: +100점
- 유사도(similarity): *30점
- 거리 가중치: max(0, 1 - distance/radius) * 50점

**3) 반경 검색 지원**

위치 정보가 있으면 기본 3km 반경 내 음식점만 조회하도록 변경하여 탐색 범위를 제한했다.

---

## 부하 테스트 결과 비교

### 테스트 조건

- 도구: k6
- API: `POST /api/v1/search`
- 시나리오: 60초 동안 VU를 점진적으로 증가
- Rate Limit: 500 req/s (Caddy)

### 개선 전 (쿼리 최적화 이전)

| VU | 성공률 | 실패율 | 평균 응답 | P95 응답 | 처리량 |
|----|--------|--------|-----------|----------|--------|
| 300 | 75% | 24.5% | 8.01s | 30s | 20 req/s |
| 600 | 60% | 39.7% | 12.37s | 30s | 24 req/s |
| 1,000 | 39% | 60.8% | 18.52s | 30s | 28 req/s |

대부분의 실패가 30초 커넥션 타임아웃으로 발생했다.

### 개선 후 (전체 조치 적용)

| VU | 성공률 | 실패율 | 평균 응답 | P95 응답 | 처리량 |
|----|--------|--------|-----------|----------|--------|
| 300 | **100%** | 0% | 1.37s | 2.84s | 108 req/s |
| 600 | **100%** | 0% | 1.48s | 3.09s | 201 req/s |
| 1,000 | **100%** | 0% | 1.80s | 3.82s | 276 req/s |

### 개선 효과 요약 (VU 1,000 기준)

| 지표 | 개선 전 | 개선 후 | 변화 |
|------|---------|---------|------|
| 성공률 | 39% | 100% | +61%p |
| 평균 응답 시간 | 18.52s | 1.80s | 10x 개선 |
| P95 응답 시간 | 30s (타임아웃) | 3.82s | 7.8x 개선 |
| 처리량 | 28 req/s | 276 req/s | 9.8x 개선 |
| 실패 요청 수 | 1,566건 | 0건 | 100% 제거 |

---

## 적용된 변경 사항 요약

| # | 문제 | 원인 | 조치 | 변경 파일 |
|---|------|------|------|-----------|
| 1 | 커넥션 풀 고갈 | 기본값 10개 사용 | pool-size 50으로 증가 | `application.prod.yml` |
| 2 | Disk I/O 과부하 | DEBUG 로그 폭주 | INFO 전환 + 비동기 Appender | `logback-spring.xml` |
| 3 | 웹훅 폭주 | 에러마다 웹훅 전송 | 웹훅 비활성화 옵션 추가 | `application.dev.yml` |
| 4 | 커넥션 2배 소비 | REQUIRES_NEW 전파 | @Async 비동기 전환 | `SearchHistoryRecorder.java` |
| 5 | 동시성 Race Condition | SELECT-then-INSERT | 유니크 인덱스 추가 | Flyway 마이그레이션 |
| 6 | 검색 쿼리 느림 | LIKE '%keyword%' FTS | pg_trgm + GIN 인덱스 | Flyway 마이그레이션 |
| 7 | 커넥션 타임아웃 길음 | 30초 기본값 | 10초로 단축 | `application.*.yml` |

---

## 인프라 개선 과제

이번 장애를 통해 드러난 구조적 문제점과 개선 방향이다.

### 해결 완료

- HikariCP 커넥션 풀 적정 설정
- 로그 레벨 및 비동기 Appender 적용
- Caddy Rate Limit 설정
- Grafana Alert 추가 (5xx 에러 발생 시 알림)
- HikariCP 커넥션 풀 / Tomcat 스레드 Grafana 대시보드 구축

### 미해결 (향후 개선 필요)

| 우선순위 | 항목 | 현황 |
|---------|------|------|
| 1 | ~~헬스체크 강화~~ | ~~DB 커넥션 고갈 시에도 200 OK 반환. 실제 DB 쿼리 기반 헬스체크 필요~~ |
| 2 | 고가용성 구성 | 단일 인스턴스 운영 중. 다중 인스턴스 + 로드밸런싱 필요 |
| 3 | SLO/SLI 정의 | 장애 기준 모호. 가용성 99.9%, 에러율 <0.1%, P95 <500ms 목표 |

---

## 교훈

1. **기본값에 의존하지 않는다** - Spring Boot 기본값은 개발 환경 기준이다. Production 설정은 반드시 명시적으로 정의한다.
2. **DEBUG 로그는 선택적으로** - Dev 환경이라도 root 레벨은 INFO로 유지하고, 필요한 패키지만 DEBUG로 설정한다. Third-party 라이브러리의 DEBUG 로그는 보안 정보를 포함할 수 있다.
3. **REQUIRES_NEW의 숨겨진 비용** - 독립 트랜잭션은 커넥션을 2배로 사용하며, 동기 호출이므로 부모 커넥션도 대기한다. 부수 효과는 비동기로 분리한다.
4. **와일드카드 LIKE 검색은 확장되지 않는다** - `LIKE '%keyword%'`는 인덱스를 사용할 수 없다. pg_trgm, Full-Text Search 등 전용 인덱스가 필요하다.
5. **모니터링과 알림은 필수 인프라** - 로그만으로는 장애를 실시간 감지할 수 없다. 메트릭 수집 + 자동 알림 체계가 갖춰져야 한다.
6. **부하 테스트로 검증한다** - 설정 변경 후 반드시 부하 테스트로 효과를 정량적으로 확인한다.

---

**문서 작성일**: 2026-02-08
**작성자**: clay.kim(김선준)
